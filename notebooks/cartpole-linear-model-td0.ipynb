{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Of Contents\n",
    "\n",
    "- [SARSA](#SARSA)\n",
    "- [SARSA with scikit-learn function approximator](#SARSA-with-scikit-learn-function-approximator)\n",
    "- [Q-learning](#Q-learning)\n",
    "- [Q-learning with custom Keras function approximator](#Q-learning-with-custom-Keras-function-approximator)\n",
    "- [Q-learning with type-II model](#Q-learning-with-type-II-model)\n",
    "- [Expected-SARSA](#Expected-SARSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed after 12 steps\n",
      "failed after 43 steps\n",
      "failed after 17 steps\n",
      "failed after 24 steps\n",
      "failed after 11 steps\n",
      "failed after 53 steps\n",
      "failed after 134 steps\n",
      "failed after 39 steps\n",
      "failed after 80 steps\n",
      "failed after 108 steps\n",
      "failed after 177 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "failed after 187 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "num_consecutive_successes = 5\n",
      "num_consecutive_successes = 6\n",
      "num_consecutive_successes = 7\n",
      "num_consecutive_successes = 8\n",
      "num_consecutive_successes = 9\n",
      "num_consecutive_successes = 10\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from keras_gym.value_functions import LinearQ\n",
    "from keras_gym.policies import ValuePolicy\n",
    "from keras_gym.algorithms import Sarsa\n",
    "\n",
    "\n",
    "\n",
    "# the Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "# define Q, its induced policy and update algorithm\n",
    "Q = LinearQ(env, lr=0.08, interaction='elementwise_quadratic')\n",
    "policy = ValuePolicy(Q)\n",
    "algo = Sarsa(Q, gamma=0.8)\n",
    "\n",
    "\n",
    "# number of iterations\n",
    "num_episodes = 200\n",
    "max_episode_steps = env._max_episode_steps\n",
    "\n",
    "\n",
    "# used for early stopping\n",
    "num_consecutive_successes = 0\n",
    "\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    last_episode = episode == num_episodes or num_consecutive_successes == 9\n",
    "    \n",
    "    # init\n",
    "    s = env.reset()\n",
    "    a = env.action_space.sample()\n",
    "    \n",
    "    # amount of random exploration\n",
    "    if last_episode:\n",
    "        epsilon = 0\n",
    "        env.render()\n",
    "    elif episode < 10:\n",
    "        epsilon = 0.5\n",
    "    else:\n",
    "        epsilon = 0.01\n",
    "    \n",
    "    for t in range(1, max_episode_steps + 1):\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        a_next = policy.epsilon_greedy(s, epsilon)\n",
    "        \n",
    "        # update or render\n",
    "        if not last_episode:\n",
    "            algo.update(s, a, r, s_next, a_next)         \n",
    "        else:\n",
    "            env.render()\n",
    "        \n",
    "        # keep track of consecutive successes\n",
    "        if done:\n",
    "            if t == max_episode_steps:\n",
    "                num_consecutive_successes += 1\n",
    "                print(f\"num_consecutive_successes = {num_consecutive_successes}\")\n",
    "            else:\n",
    "                num_consecutive_successes = 0\n",
    "                print(f\"failed after {t} steps\")\n",
    "            break\n",
    "    \n",
    "        # prepare for next step\n",
    "        s, a = s_next, a_next\n",
    "\n",
    "        \n",
    "    if last_episode:\n",
    "        break\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA with scikit-learn function approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed after 15 steps\n",
      "failed after 22 steps\n",
      "failed after 12 steps\n",
      "failed after 13 steps\n",
      "failed after 33 steps\n",
      "failed after 36 steps\n",
      "failed after 29 steps\n",
      "failed after 8 steps\n",
      "failed after 20 steps\n",
      "failed after 14 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 39 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 25 steps\n",
      "failed after 31 steps\n",
      "failed after 9 steps\n",
      "failed after 29 steps\n",
      "failed after 29 steps\n",
      "failed after 14 steps\n",
      "failed after 27 steps\n",
      "failed after 10 steps\n",
      "failed after 34 steps\n",
      "failed after 17 steps\n",
      "failed after 47 steps\n",
      "failed after 8 steps\n",
      "failed after 23 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 8 steps\n",
      "failed after 11 steps\n",
      "failed after 58 steps\n",
      "failed after 12 steps\n",
      "failed after 26 steps\n",
      "failed after 11 steps\n",
      "failed after 10 steps\n",
      "failed after 11 steps\n",
      "failed after 10 steps\n",
      "failed after 43 steps\n",
      "failed after 10 steps\n",
      "failed after 36 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 32 steps\n",
      "failed after 125 steps\n",
      "failed after 121 steps\n",
      "failed after 47 steps\n",
      "failed after 120 steps\n",
      "failed after 68 steps\n",
      "failed after 146 steps\n",
      "failed after 163 steps\n",
      "failed after 28 steps\n",
      "failed after 61 steps\n",
      "failed after 51 steps\n",
      "failed after 47 steps\n",
      "failed after 67 steps\n",
      "failed after 62 steps\n",
      "failed after 188 steps\n",
      "failed after 125 steps\n",
      "failed after 103 steps\n",
      "failed after 179 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 163 steps\n",
      "failed after 125 steps\n",
      "failed after 50 steps\n",
      "failed after 114 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "failed after 99 steps\n",
      "failed after 88 steps\n",
      "failed after 57 steps\n",
      "failed after 175 steps\n",
      "failed after 117 steps\n",
      "failed after 161 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 157 steps\n",
      "failed after 113 steps\n",
      "failed after 53 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 160 steps\n",
      "failed after 190 steps\n",
      "failed after 127 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 187 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 134 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "failed after 162 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "num_consecutive_successes = 5\n",
      "num_consecutive_successes = 6\n",
      "num_consecutive_successes = 7\n",
      "num_consecutive_successes = 8\n",
      "num_consecutive_successes = 9\n",
      "num_consecutive_successes = 10\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from keras_gym.value_functions import GenericQ\n",
    "from keras_gym.policies import ValuePolicy\n",
    "from keras_gym.algorithms import Sarsa\n",
    "from keras_gym.wrappers import SklearnModelWrapper\n",
    "\n",
    "\n",
    "# the Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "# define sklearn model for approximating Q-function\n",
    "model = SklearnModelWrapper(\n",
    "    estimator=SGDRegressor(eta0=0.08, learning_rate='constant'),\n",
    "    transformer=FunctionTransformer(\n",
    "        lambda x: np.hstack([x, x ** 2]), validate=False),\n",
    ")\n",
    "\n",
    "\n",
    "# define Q, its induced policy and update algorithm\n",
    "Q = GenericQ(env, model)\n",
    "policy = ValuePolicy(Q)\n",
    "algo = Sarsa(Q, gamma=0.8)\n",
    "\n",
    "\n",
    "# number of iterations\n",
    "num_episodes = 200\n",
    "max_episode_steps = env._max_episode_steps\n",
    "\n",
    "\n",
    "# used for early stopping\n",
    "num_consecutive_successes = 0\n",
    "\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    last_episode = episode == num_episodes or num_consecutive_successes == 9\n",
    "    \n",
    "    # init\n",
    "    s = env.reset()\n",
    "    a = env.action_space.sample()\n",
    "    \n",
    "    # amount of random exploration\n",
    "    if last_episode:\n",
    "        epsilon = 0\n",
    "        env.render()\n",
    "    elif episode < 10:\n",
    "        epsilon = 0.5\n",
    "    else:\n",
    "        epsilon = 0.01\n",
    "    \n",
    "    for t in range(1, max_episode_steps + 1):\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        a_next = policy.epsilon_greedy(s, epsilon)\n",
    "        \n",
    "        # update or render\n",
    "        if not last_episode:\n",
    "            algo.update(s, a, r, s_next, a_next)         \n",
    "        else:\n",
    "            env.render()\n",
    "        \n",
    "        # keep track of consecutive successes\n",
    "        if done:\n",
    "            if t == max_episode_steps:\n",
    "                num_consecutive_successes += 1\n",
    "                print(f\"num_consecutive_successes = {num_consecutive_successes}\")\n",
    "            else:\n",
    "                num_consecutive_successes = 0\n",
    "                print(f\"failed after {t} steps\")\n",
    "            break\n",
    "    \n",
    "        # prepare for next step\n",
    "        s, a = s_next, a_next\n",
    "\n",
    "        \n",
    "    if last_episode:\n",
    "        break\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed after 16 steps\n",
      "failed after 14 steps\n",
      "failed after 24 steps\n",
      "failed after 12 steps\n",
      "failed after 15 steps\n",
      "failed after 14 steps\n",
      "failed after 17 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 13 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 113 steps\n",
      "failed after 77 steps\n",
      "failed after 130 steps\n",
      "failed after 75 steps\n",
      "failed after 56 steps\n",
      "failed after 160 steps\n",
      "failed after 71 steps\n",
      "failed after 147 steps\n",
      "failed after 133 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 71 steps\n",
      "failed after 94 steps\n",
      "failed after 85 steps\n",
      "failed after 79 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 86 steps\n",
      "failed after 100 steps\n",
      "failed after 69 steps\n",
      "failed after 79 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 74 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 89 steps\n",
      "failed after 65 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "num_consecutive_successes = 5\n",
      "num_consecutive_successes = 6\n",
      "num_consecutive_successes = 7\n",
      "failed after 192 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "failed after 131 steps\n",
      "failed after 89 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 84 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 65 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "num_consecutive_successes = 5\n",
      "num_consecutive_successes = 6\n",
      "failed after 79 steps\n",
      "failed after 86 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 191 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "failed after 75 steps\n",
      "failed after 155 steps\n",
      "failed after 83 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 174 steps\n",
      "failed after 158 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 147 steps\n",
      "failed after 69 steps\n",
      "failed after 72 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 69 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 186 steps\n",
      "failed after 119 steps\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras_gym.value_functions import LinearQ\n",
    "from keras_gym.policies import ValuePolicy\n",
    "from keras_gym.algorithms import QLearning\n",
    "\n",
    "\n",
    "# the Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "# define Q, its induced policy and update algorithm\n",
    "Q = LinearQ(env, interaction='elementwise_quadratic', lr=0.8, momentum=0., decay=0.1)\n",
    "policy = ValuePolicy(Q)\n",
    "algo = QLearning(Q, gamma=0.8)\n",
    "\n",
    "\n",
    "# number of iterations\n",
    "num_episodes = 100\n",
    "max_episode_steps = env._max_episode_steps\n",
    "\n",
    "\n",
    "# used for early stopping\n",
    "num_consecutive_successes = 0\n",
    "\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    last_episode = episode == num_episodes or num_consecutive_successes == 9\n",
    "    \n",
    "    # init\n",
    "    s = env.reset()\n",
    "    \n",
    "    # amount of random exploration\n",
    "    if last_episode:\n",
    "        epsilon = 0\n",
    "        env.render()\n",
    "    elif episode < 10:\n",
    "        epsilon = 0.5\n",
    "    else:\n",
    "        epsilon = 0.01\n",
    "    \n",
    "    for t in range(1, max_episode_steps + 1):\n",
    "        a = policy.epsilon_greedy(s, epsilon)\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        \n",
    "        # update or render\n",
    "        if not last_episode:          \n",
    "            algo.update(s, a, r, s_next)            \n",
    "        else:\n",
    "            env.render()\n",
    "        \n",
    "        # keep track of consecutive successes\n",
    "        if done:\n",
    "            if t == max_episode_steps:\n",
    "                num_consecutive_successes += 1\n",
    "                print(f\"num_consecutive_successes = {num_consecutive_successes}\")\n",
    "            else:\n",
    "                num_consecutive_successes = 0\n",
    "                print(f\"failed after {t} steps\")\n",
    "            break\n",
    "    \n",
    "        # prepare for next step\n",
    "        s = s_next\n",
    "\n",
    "        \n",
    "    if last_episode:\n",
    "        break\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning with custom Keras function approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed after 15 steps\n",
      "failed after 12 steps\n",
      "failed after 13 steps\n",
      "failed after 11 steps\n",
      "failed after 18 steps\n",
      "failed after 12 steps\n",
      "failed after 9 steps\n",
      "failed after 11 steps\n",
      "failed after 12 steps\n",
      "failed after 28 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 18 steps\n",
      "failed after 157 steps\n",
      "failed after 113 steps\n",
      "failed after 195 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 86 steps\n",
      "failed after 73 steps\n",
      "failed after 132 steps\n",
      "failed after 105 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 162 steps\n",
      "failed after 86 steps\n",
      "failed after 91 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 159 steps\n",
      "failed after 129 steps\n",
      "failed after 132 steps\n",
      "failed after 193 steps\n",
      "failed after 117 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 111 steps\n",
      "failed after 156 steps\n",
      "failed after 125 steps\n",
      "failed after 95 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 66 steps\n",
      "failed after 115 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 124 steps\n",
      "failed after 80 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 144 steps\n",
      "failed after 97 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 108 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 119 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "num_consecutive_successes = 5\n",
      "num_consecutive_successes = 6\n",
      "num_consecutive_successes = 7\n",
      "num_consecutive_successes = 8\n",
      "num_consecutive_successes = 9\n",
      "num_consecutive_successes = 10\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras_gym.value_functions import GenericQ\n",
    "from keras_gym.policies import ValuePolicy\n",
    "from keras_gym.algorithms import QLearning\n",
    "\n",
    "\n",
    "# the Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "# custom function apprixmator (linear regression)  \n",
    "model = keras.Sequential(layers=[\n",
    "    keras.layers.Lambda(lambda x: K.concatenate([x, x ** 2])),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(lr=0.05, momentum=0.5),\n",
    "    loss=keras.metrics.mean_squared_error)\n",
    "\n",
    "\n",
    "# define Q, its induced policy and update algorithm\n",
    "Q = GenericQ(env, model)\n",
    "policy = ValuePolicy(Q)\n",
    "algo = QLearning(Q, gamma=0.8)\n",
    "\n",
    "\n",
    "# number of iterations\n",
    "num_episodes = 100\n",
    "max_episode_steps = env._max_episode_steps\n",
    "\n",
    "\n",
    "# used for early stopping\n",
    "num_consecutive_successes = 0\n",
    "\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    last_episode = episode == num_episodes or num_consecutive_successes == 9\n",
    "    \n",
    "    # init\n",
    "    s = env.reset()\n",
    "    \n",
    "    # amount of random exploration\n",
    "    if last_episode:\n",
    "        epsilon = 0\n",
    "        env.render()\n",
    "    elif episode < 10:\n",
    "        epsilon = 0.5\n",
    "    else:\n",
    "        epsilon = 0.01\n",
    "    \n",
    "    for t in range(1, max_episode_steps + 1):\n",
    "        a = policy.epsilon_greedy(s, epsilon)\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        \n",
    "        # update or render\n",
    "        if not last_episode:\n",
    "            algo.update(s, a, r, s_next)            \n",
    "        else:\n",
    "            env.render()\n",
    "        \n",
    "        # keep track of consecutive successes\n",
    "        if done:\n",
    "            if t == max_episode_steps:\n",
    "                num_consecutive_successes += 1\n",
    "                print(f\"num_consecutive_successes = {num_consecutive_successes}\")\n",
    "            else:\n",
    "                num_consecutive_successes = 0\n",
    "                print(f\"failed after {t} steps\")\n",
    "            break\n",
    "    \n",
    "        # prepare for next step\n",
    "        s = s_next\n",
    "\n",
    "        \n",
    "    if last_episode:\n",
    "        break\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning with type-II model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed after 30 steps\n",
      "failed after 20 steps\n",
      "failed after 12 steps\n",
      "failed after 10 steps\n",
      "failed after 16 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 14 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 15 steps\n",
      "failed after 24 steps\n",
      "failed after 94 steps\n",
      "failed after 72 steps\n",
      "failed after 42 steps\n",
      "failed after 49 steps\n",
      "failed after 85 steps\n",
      "failed after 105 steps\n",
      "failed after 24 steps\n",
      "failed after 38 steps\n",
      "failed after 50 steps\n",
      "failed after 55 steps\n",
      "failed after 47 steps\n",
      "failed after 168 steps\n",
      "failed after 63 steps\n",
      "failed after 52 steps\n",
      "failed after 123 steps\n",
      "failed after 60 steps\n",
      "failed after 44 steps\n",
      "failed after 137 steps\n",
      "failed after 63 steps\n",
      "failed after 93 steps\n",
      "failed after 61 steps\n",
      "failed after 128 steps\n",
      "failed after 56 steps\n",
      "failed after 75 steps\n",
      "failed after 148 steps\n",
      "failed after 77 steps\n",
      "failed after 76 steps\n",
      "failed after 175 steps\n",
      "failed after 67 steps\n",
      "failed after 71 steps\n",
      "failed after 127 steps\n",
      "failed after 166 steps\n",
      "failed after 9 steps\n",
      "failed after 46 steps\n",
      "failed after 69 steps\n",
      "failed after 106 steps\n",
      "failed after 68 steps\n",
      "failed after 48 steps\n",
      "failed after 80 steps\n",
      "failed after 54 steps\n",
      "failed after 49 steps\n",
      "failed after 64 steps\n",
      "failed after 71 steps\n",
      "failed after 72 steps\n",
      "failed after 102 steps\n",
      "failed after 67 steps\n",
      "failed after 68 steps\n",
      "failed after 87 steps\n",
      "failed after 79 steps\n",
      "failed after 71 steps\n",
      "failed after 96 steps\n",
      "failed after 63 steps\n",
      "failed after 63 steps\n",
      "failed after 64 steps\n",
      "failed after 178 steps\n",
      "failed after 76 steps\n",
      "failed after 82 steps\n",
      "failed after 67 steps\n",
      "failed after 102 steps\n",
      "failed after 83 steps\n",
      "failed after 92 steps\n",
      "failed after 88 steps\n",
      "failed after 99 steps\n",
      "failed after 89 steps\n",
      "failed after 102 steps\n",
      "failed after 69 steps\n",
      "failed after 119 steps\n",
      "failed after 127 steps\n",
      "failed after 59 steps\n",
      "failed after 90 steps\n",
      "failed after 127 steps\n",
      "failed after 70 steps\n",
      "failed after 136 steps\n",
      "failed after 78 steps\n",
      "failed after 114 steps\n",
      "failed after 84 steps\n",
      "failed after 68 steps\n",
      "failed after 108 steps\n",
      "failed after 82 steps\n",
      "failed after 111 steps\n",
      "failed after 99 steps\n",
      "failed after 79 steps\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras_gym.value_functions import LinearQ\n",
    "from keras_gym.policies import ValuePolicy\n",
    "from keras_gym.algorithms import QLearning\n",
    "\n",
    "\n",
    "# the Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "# define Q, its induced policy and update algorithm\n",
    "Q = LinearQ(env, model_type=2, lr=0.05, momentum=0.5, interaction='elementwise_quadratic')\n",
    "policy = ValuePolicy(Q)\n",
    "algo = QLearning(Q, gamma=0.8)\n",
    "\n",
    "\n",
    "# number of iterations\n",
    "num_episodes = 100\n",
    "max_episode_steps = env._max_episode_steps\n",
    "\n",
    "\n",
    "# used for early stopping\n",
    "num_consecutive_successes = 0\n",
    "\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    last_episode = episode == num_episodes or num_consecutive_successes == 9\n",
    "    \n",
    "    # init\n",
    "    s = env.reset()\n",
    "    \n",
    "    # amount of random exploration\n",
    "    if last_episode:\n",
    "        epsilon = 0\n",
    "        env.render()\n",
    "    elif episode < 10:\n",
    "        epsilon = 0.5\n",
    "    else:\n",
    "        epsilon = 0.01\n",
    "    \n",
    "    for t in range(1, max_episode_steps + 1):\n",
    "        a = policy.epsilon_greedy(s, epsilon)\n",
    "        s_next, r, done, info = env.step(a)\n",
    "\n",
    "        \n",
    "        # update or render\n",
    "        if not last_episode:\n",
    "            algo.update(s, a, r, s_next)         \n",
    "        else:\n",
    "            env.render()\n",
    "        \n",
    "        # keep track of consecutive successes\n",
    "        if done:\n",
    "            if t == max_episode_steps:\n",
    "                num_consecutive_successes += 1\n",
    "                print(f\"num_consecutive_successes = {num_consecutive_successes}\")\n",
    "            else:\n",
    "                num_consecutive_successes = 0\n",
    "                print(f\"failed after {t} steps\")\n",
    "            break\n",
    "    \n",
    "        # prepare for next step\n",
    "        s = s_next\n",
    "\n",
    "        \n",
    "    if last_episode:\n",
    "        break\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed after 27 steps\n",
      "failed after 21 steps\n",
      "failed after 28 steps\n",
      "failed after 17 steps\n",
      "failed after 11 steps\n",
      "failed after 11 steps\n",
      "failed after 15 steps\n",
      "failed after 13 steps\n",
      "failed after 9 steps\n",
      "failed after 12 steps\n",
      "failed after 13 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 11 steps\n",
      "failed after 10 steps\n",
      "failed after 11 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 11 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 8 steps\n",
      "failed after 9 steps\n",
      "failed after 11 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 10 steps\n",
      "failed after 9 steps\n",
      "failed after 9 steps\n",
      "failed after 11 steps\n",
      "failed after 8 steps\n",
      "failed after 13 steps\n",
      "failed after 9 steps\n",
      "failed after 8 steps\n",
      "failed after 10 steps\n",
      "failed after 14 steps\n",
      "failed after 10 steps\n",
      "failed after 36 steps\n",
      "failed after 39 steps\n",
      "failed after 33 steps\n",
      "failed after 41 steps\n",
      "failed after 49 steps\n",
      "failed after 79 steps\n",
      "failed after 96 steps\n",
      "failed after 101 steps\n",
      "failed after 104 steps\n",
      "failed after 57 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 55 steps\n",
      "failed after 57 steps\n",
      "failed after 69 steps\n",
      "failed after 69 steps\n",
      "failed after 84 steps\n",
      "failed after 133 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 73 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 84 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "failed after 125 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 66 steps\n",
      "failed after 82 steps\n",
      "failed after 65 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 70 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 67 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "failed after 141 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 57 steps\n",
      "failed after 95 steps\n",
      "failed after 89 steps\n",
      "failed after 114 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 157 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 103 steps\n",
      "failed after 116 steps\n",
      "failed after 111 steps\n",
      "failed after 157 steps\n",
      "failed after 86 steps\n",
      "failed after 89 steps\n",
      "failed after 126 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 133 steps\n",
      "failed after 82 steps\n",
      "failed after 189 steps\n",
      "failed after 165 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n",
      "failed after 136 steps\n",
      "failed after 179 steps\n",
      "failed after 85 steps\n",
      "failed after 67 steps\n",
      "failed after 189 steps\n",
      "failed after 96 steps\n",
      "failed after 86 steps\n",
      "failed after 85 steps\n",
      "failed after 80 steps\n",
      "failed after 88 steps\n",
      "failed after 158 steps\n",
      "failed after 158 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 96 steps\n",
      "failed after 78 steps\n",
      "failed after 188 steps\n",
      "failed after 130 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 104 steps\n",
      "failed after 191 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 101 steps\n",
      "failed after 87 steps\n",
      "failed after 132 steps\n",
      "failed after 95 steps\n",
      "failed after 121 steps\n",
      "failed after 191 steps\n",
      "num_consecutive_successes = 1\n",
      "failed after 177 steps\n",
      "failed after 188 steps\n",
      "failed after 102 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 112 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "failed after 77 steps\n",
      "failed after 180 steps\n",
      "num_consecutive_successes = 1\n",
      "num_consecutive_successes = 2\n",
      "num_consecutive_successes = 3\n",
      "num_consecutive_successes = 4\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras_gym.value_functions import LinearQ\n",
    "from keras_gym.policies import ValuePolicy\n",
    "from keras_gym.algorithms import ExpectedSarsa\n",
    "\n",
    "\n",
    "\n",
    "# the Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "# define Q, its induced policy and update algorithm\n",
    "Q = LinearQ(env, interaction='elementwise_quadratic', lr=0.01)\n",
    "policy = ValuePolicy(Q)\n",
    "algo = ExpectedSarsa(Q, policy, gamma=0.8)\n",
    "\n",
    "\n",
    "# number of iterations\n",
    "num_episodes = 200\n",
    "max_episode_steps = env._max_episode_steps\n",
    "\n",
    "\n",
    "# used for early stopping\n",
    "num_consecutive_successes = 0\n",
    "\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    last_episode = episode == num_episodes or num_consecutive_successes == 9\n",
    "    \n",
    "    # init\n",
    "    s = env.reset()\n",
    "    \n",
    "    # amount of random exploration\n",
    "    if last_episode:\n",
    "        epsilon = 0\n",
    "        env.render()\n",
    "    elif episode < 10:\n",
    "        epsilon = 0.5\n",
    "    else:\n",
    "        epsilon = 0.01\n",
    "    \n",
    "    for t in range(1, max_episode_steps + 1):\n",
    "        a = policy.epsilon_greedy(s, epsilon)\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        \n",
    "        # update or render\n",
    "        if not last_episode:\n",
    "            algo.update(s, a, r, s_next)            \n",
    "        else:\n",
    "            env.render()\n",
    "        \n",
    "        # keep track of consecutive successes\n",
    "        if done:\n",
    "            if t == max_episode_steps:\n",
    "                num_consecutive_successes += 1\n",
    "                print(f\"num_consecutive_successes = {num_consecutive_successes}\")\n",
    "            else:\n",
    "                num_consecutive_successes = 0\n",
    "                print(f\"failed after {t} steps\")\n",
    "            break\n",
    "    \n",
    "        # prepare for next step\n",
    "        s = s_next\n",
    "\n",
    "        \n",
    "    if last_episode:\n",
    "        break\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.wrappers.Monitor(env, os.path.join('data', 'video', 'cartpole-linear-model-sarsa'), force=True)\n",
    "# s = env.reset()\n",
    "# env.render()\n",
    "# done = False\n",
    "\n",
    "# while not done:\n",
    "#     a = policy.greedy(s)\n",
    "#     s, _, done, _ = env.step(a)\n",
    "#     env.render()\n",
    "    \n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
