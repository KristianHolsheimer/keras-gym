{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-gym -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../scripts/atari/dqn.py\n",
    "import gym\n",
    "import keras_gym as km\n",
    "from tensorflow.keras.layers import Conv2D, Lambda, Dense, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# env with preprocessing\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "env = km.wrappers.ImagePreprocessor(env, height=105, width=80, grayscale=True)\n",
    "env = km.wrappers.FrameStacker(env, num_frames=3)\n",
    "env = km.wrappers.TrainMonitor(env)\n",
    "\n",
    "# show logs from TrainMonitor\n",
    "km.enable_logging()\n",
    "\n",
    "\n",
    "class Func(km.FunctionApproximator):\n",
    "    def body(self, S):\n",
    "        def diff_transform(S):\n",
    "            S = K.cast(S, 'float32') / 255\n",
    "            M = km.utils.diff_transform_matrix(num_frames=3)\n",
    "            return K.dot(S, M)\n",
    "\n",
    "        X = Lambda(diff_transform)(S)\n",
    "        X = Conv2D(filters=16, kernel_size=8, strides=4, activation='relu')(X)\n",
    "        X = Conv2D(filters=32, kernel_size=4, strides=2, activation='relu')(X)\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(units=256, activation='relu')(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "func = Func(env, lr=0.00025)\n",
    "\n",
    "q = km.QTypeII(\n",
    "    function_approximator=func,\n",
    "    gamma=0.99,\n",
    "    bootstrap_n=1,\n",
    "    bootstrap_with_target_model=True)\n",
    "\n",
    "buffer = km.caching.ExperienceReplayBuffer.from_value_function(\n",
    "    value_function=q,\n",
    "    capacity=1000000,\n",
    "    batch_size=32)\n",
    "\n",
    "policy = km.EpsilonGreedy(q)\n",
    "\n",
    "\n",
    "# DQN update schedule\n",
    "buffer_warmup_period = 50000\n",
    "target_model_sync_period = 10000\n",
    "\n",
    "\n",
    "# DQN exploration schedule\n",
    "def epsilon(T):\n",
    "    \"\"\" stepwise linear annealing \"\"\"\n",
    "    M = 1000000\n",
    "    if T < M:\n",
    "        return 1 - 0.9 * T / M\n",
    "    if T < 2 * M:\n",
    "        return 0.1 - 0.09 * (T - M) / M\n",
    "    return 0.01\n",
    "\n",
    "\n",
    "while env.T < 3000000:\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(env.spec.max_episode_steps):\n",
    "        policy.epsilon = epsilon(env.T)\n",
    "        a = policy(s)\n",
    "        s_next, r, done, info = env.step(a)\n",
    "\n",
    "        buffer.add(s, a, r, done, env.ep)\n",
    "\n",
    "        if env.T > buffer_warmup_period:\n",
    "            q.batch_update(*buffer.sample())\n",
    "\n",
    "        if env.T % target_model_sync_period == 0:\n",
    "            q.sync_target_model()\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "    # generate an animated GIF to see what's going on\n",
    "    if env.ep % 10 == 0 and env.T > buffer_warmup_period:\n",
    "        km.utils.generate_gif(\n",
    "            env=env,\n",
    "            policy=policy.set_epsilon(0.01),\n",
    "            filepath='./data/dqn/gifs/ep{:06d}.gif'.format(env.ep),\n",
    "            resize_to=(320, 420))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
