Non-Slippery Frozen Lake with PPO
=================================

In this notebook we solve a non-slippery version of the `FrozenLake-v0
<https://gym.openai.com/envs/FrozenLake-v0/>`_ environment using the `PPO
<https://arxiv.org/abs/1707.06347>`_ algorithm. We'll use a linear function
approximator for our :term:`policy <updateable policy>` and our :term:`state
value function`.


GitHub version
--------------

.. raw:: html

    <p>
    For an up-to-date version of this notebook, see the GitHub version <a href="https://github.com/KristianHolsheimer/keras-gym/blob/master/notebooks/frozen_lake/ppo.ipynb" target="_blank" style="font-weight:bold">here</a>.
    </p>


Notebook
--------

.. raw:: html

    <p>
    To view the below notebook in a new tab, click <a href="../../_static/notebooks/frozen_lake/ppo.html" target="_blank" style="font-weight:bold">here</a>.
    </p>

    <iframe width="100%" height="600px" src="../../_static/notebooks/frozen_lake/ppo.html"></iframe>
